
"""
–ê–ª–≥–æ—Ä–∏—Ç–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º fuzzy matching
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ –≤–µ—Å–∞
"""

from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
import re
from difflib import SequenceMatcher
import json
import logging

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    from fuzzywuzzy import fuzz, process
    FUZZYWUZZY_AVAILABLE = True
except ImportError:
    FUZZYWUZZY_AVAILABLE = False
    print("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ fuzzywuzzy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º.")

@dataclass
class MatchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤"""
    product_1c_id: str
    product_1c_name: str
    scraped_product_title: str
    marketplace: str
    similarity_score: float
    price_1c: float
    price_scraped: float
    price_difference: float
    price_difference_percent: float
    confidence: str  # "high", "medium", "low"
    match_details: Dict[str, float]  # –î–µ—Ç–∞–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
    url: str = ""  # URL —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–µ
    reviews_count: int = 0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –ø—Ä–æ–¥–∞–≤—Ü–∞
    rating: float = 0.0  # –†–µ–π—Ç–∏–Ω–≥ –ø—Ä–æ–¥–∞–≤—Ü–∞

    def to_dict(self):
        return {
            'product_1c_id': self.product_1c_id,
            'product_1c_name': self.product_1c_name,
            'scraped_product_title': self.scraped_product_title,
            'marketplace': self.marketplace,
            'similarity_score': round(self.similarity_score, 2),
            'price_1c': self.price_1c,
            'price_scraped': self.price_scraped,
            'price_difference': round(self.price_difference, 2),
            'price_difference_percent': round(self.price_difference_percent, 2),
            'confidence': self.confidence,
            'match_details': {k: round(v, 2) for k, v in self.match_details.items()},
            'url': self.url,
            'reviews_count': self.reviews_count,
            'rating': round(self.rating, 1) if self.rating > 0 else 0.0
        }

class ProductMatcher:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–° —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""

    def __init__(self, config_file: str = "matching_config.json"):
        self.config = self._load_config(config_file)
        self.logger = logging.getLogger(__name__)

    def _load_config(self, config_file: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
        default_config = {
            "threshold": 0.85,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            "weights": {
                "name": 0.7,     # –í–µ—Å –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ (—É–≤–µ–ª–∏—á–µ–Ω —Å 0.6)
                "brand": 0.2,    # –í–µ—Å –±—Ä–µ–Ω–¥–∞
                "size": 0.1      # –í–µ—Å —Ä–∞–∑–º–µ—Ä–∞ (—É–≤–µ–ª–∏—á–µ–Ω —Å 0.15)
            },
            "algorithms": [
                "levenshtein",
                "token_similarity", 
                "fuzzy_ratio"
            ],
            "preprocessing": {
                "normalize_case": True,
                "remove_special_chars": True,
                "normalize_spaces": True,
                "common_replacements": {
                    "–º–æ—Ç–æ—à–ª–µ–º": "—à–ª–µ–º",
                    "helmet": "—à–ª–µ–º",
                    "—Ä–∞–∑–º–µ—Ä": "",
                    "size": "",
                    "—Ü–≤–µ—Ç": "",
                    "color": ""
                }
            },
            "confidence_levels": {
                "high": 0.9,
                "medium": 0.7,
                "low": 0.5
            }
        }

        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            self.logger.info(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, ensure_ascii=False, indent=2)
            return default_config

    def match_products(self, products_1c: List[Dict], scraped_products: List[Dict], threshold: float = None) -> List[MatchResult]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –∏–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        match_threshold = threshold if threshold is not None else self.config['threshold']
        
        self.logger.info(f"üîç –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: –ø–æ—Ä–æ–≥={match_threshold}, —Ç–æ–≤–∞—Ä–æ–≤ 1–°={len(products_1c)}, —Å–ø–∞—Ä—Å–µ–Ω–æ={len(scraped_products)}")
        
        matches = []
        top_scores = []  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-5 –ª—É—á—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π

        for idx, product_1c in enumerate(products_1c):
            # –í–∫–ª—é—á–∞–µ–º –æ—Ç–ª–∞–¥–∫—É –¥–ª—è –ø–µ—Ä–≤—ã—Ö 2 —Ç–æ–≤–∞—Ä–æ–≤
            debug_mode = (idx < 2)
            best_matches = self._find_best_matches(product_1c, scraped_products, debug=debug_mode)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–∂–µ—Å—Ç–∏
            best_matches.sort(key=lambda x: x.similarity_score, reverse=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-3 –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            for match in best_matches[:3]:
                top_scores.append({
                    'product_1c': product_1c.get('name', '')[:50],
                    'scraped': match.scraped_product_title[:50],
                    'score': match.similarity_score,
                    'marketplace': match.marketplace
                })

            for match in best_matches:
                if match.similarity_score >= match_threshold:
                    matches.append(match)
        
        # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-5 –ª—É—á—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if top_scores:
            top_scores.sort(key=lambda x: x['score'], reverse=True)
            self.logger.info(f"üìä –¢–æ–ø-5 –ª—É—á—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (–≤—Å–µ —Å–∞–π—Ç—ã):")
            for i, item in enumerate(top_scores[:5], 1):
                self.logger.info(f"   {i}. {item['score']:.2%} | {item['marketplace']} | {item['product_1c']} ‚Üî {item['scraped']}")

        self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ {match_threshold:.0%}: {len(matches)}")
        return sorted(matches, key=lambda x: x.similarity_score, reverse=True)

    def _find_best_matches(self, product_1c: Dict, scraped_products: List[Dict], debug: bool = False) -> List[MatchResult]:
        """–ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è —Ç–æ–≤–∞—Ä–∞ –∏–∑ 1–°"""
        matches = []
        
        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ - —Å—á–∏—Ç–∞–µ–º —Ç–æ–≤–∞—Ä—ã –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        if debug:
            sources_count = {}
            for scraped in scraped_products:
                source = scraped.get('source', scraped.get('marketplace', 'unknown'))
                sources_count[source] = sources_count.get(source, 0) + 1
            if sources_count:
                self.logger.info(f"   üìä –¢–æ–≤–∞—Ä—ã –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º: {sources_count}")

        # –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –¥–∞–∂–µ —Å –Ω–∏–∑–∫–∏–º score (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞)
        all_scores = []  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏
        
        for scraped in scraped_products:
            similarity = self._calculate_similarity(product_1c, scraped)
            score = similarity['total_score']
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if debug:
                all_scores.append({
                    'score': score,
                    'title': scraped.get('title', '')[:60],
                    'source': scraped.get('source', scraped.get('marketplace', 'unknown'))
                })

            # –°–æ–∑–¥–∞–µ–º match –¥–ª—è –í–°–ï–• —Ç–æ–≤–∞—Ä–æ–≤ (—É–±—Ä–∞–ª–∏ —Ñ–∏–ª—å—Ç—Ä –ø–æ confidence_levels['low'])
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ threshold –±—É–¥–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ—Ç–æ–¥–µ match_products
            price_1c = float(product_1c.get('price', 0))
            price_scraped = float(scraped.get('price', 0))
            price_diff = price_scraped - price_1c
            price_diff_percent = (price_diff / price_1c * 100) if price_1c > 0 else 0

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence = self._get_confidence_level(score)

            match = MatchResult(
                product_1c_id=product_1c.get('id', ''),
                product_1c_name=product_1c.get('name', ''),
                scraped_product_title=scraped.get('title', ''),
                marketplace=scraped.get('source', scraped.get('marketplace', '')),
                similarity_score=score,
                price_1c=price_1c,
                price_scraped=price_scraped,
                price_difference=price_diff,
                price_difference_percent=price_diff_percent,
                confidence=confidence,
                match_details=similarity['details'],
                url=scraped.get('url', ''),
                reviews_count=scraped.get('reviews_count', 0),
                rating=scraped.get('rating', 0.0)
            )
            matches.append(match)
        
        # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-5 –æ—Ü–µ–Ω–æ–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if debug and all_scores:
            all_scores.sort(key=lambda x: x['score'], reverse=True)
            self.logger.info(f"   üîç –¢–æ–ø-5 –æ—Ü–µ–Ω–æ–∫ –¥–ª—è '{product_1c.get('name', '')[:50]}':")
            for i, item in enumerate(all_scores[:5], 1):
                self.logger.info(f"      {i}. {item['score']:.2%} | {item['source']} | {item['title']}")

        return matches

    def _calculate_similarity(self, product_1c: Dict, scraped_product: Dict) -> Dict[str, any]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É —Ç–æ–≤–∞—Ä–∞–º–∏"""
        weights = self.config['weights']
        details = {}

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π
        name_1c = self._preprocess_text(product_1c.get('name', ''))
        name_scraped = self._preprocess_text(scraped_product.get('title', ''))
        name_similarity = self._compare_texts(name_1c, name_scraped)
        details['name'] = name_similarity

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–æ–≤
        brand_1c = self._preprocess_text(product_1c.get('brand', ''))
        brand_scraped = self._extract_brand_from_title(scraped_product.get('title', ''))
        brand_similarity = self._compare_texts(brand_1c, brand_scraped) if brand_1c and brand_scraped else 0.5
        details['brand'] = brand_similarity

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
        size_1c = product_1c.get('size', '').upper()
        size_scraped = self._extract_size_from_title(scraped_product.get('title', ''))
        size_similarity = 1.0 if size_1c == size_scraped else (0.5 if size_1c and size_scraped else 0.7)
        details['size'] = size_similarity

        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É (–∫–∞—Ç–µ–≥–æ—Ä–∏—è —É–±—Ä–∞–Ω–∞)
        total_score = (
            name_similarity * weights['name'] +
            brand_similarity * weights['brand'] +
            size_similarity * weights['size']
        )

        return {
            'total_score': total_score,
            'details': details
        }

    def _compare_texts(self, text1: str, text2: str) -> float:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤"""
        if not text1 or not text2:
            return 0.0

        scores = []

        # –ê–ª–≥–æ—Ä–∏—Ç–º 1: SequenceMatcher (–±–∞–∑–æ–≤—ã–π)
        if "levenshtein" in self.config['algorithms']:
            seq_score = SequenceMatcher(None, text1, text2).ratio()
            scores.append(seq_score)

        # –ê–ª–≥–æ—Ä–∏—Ç–º 2: –¢–æ–∫–µ–Ω–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        if "token_similarity" in self.config['algorithms']:
            token_score = self._token_similarity(text1, text2)
            scores.append(token_score)

        # –ê–ª–≥–æ—Ä–∏—Ç–º 3: FuzzyWuzzy (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
        if "fuzzy_ratio" in self.config['algorithms'] and FUZZYWUZZY_AVAILABLE:
            fuzzy_score = fuzz.ratio(text1, text2) / 100.0
            scores.append(fuzzy_score)

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã FuzzyWuzzy
            token_sort_score = fuzz.token_sort_ratio(text1, text2) / 100.0
            token_set_score = fuzz.token_set_ratio(text1, text2) / 100.0
            scores.extend([token_sort_score, token_set_score])

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∏–ª–∏ —Å—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä
        return max(scores) if scores else 0.0

    def _token_similarity(self, text1: str, text2: str) -> float:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ —Ç–æ–∫–µ–Ω–∞–º"""
        tokens1 = set(text1.lower().split())
        tokens2 = set(text2.lower().split())

        if not tokens1 or not tokens2:
            return 0.0

        intersection = tokens1.intersection(tokens2)
        union = tokens1.union(tokens2)

        return len(intersection) / len(union) if union else 0.0

    def _preprocess_text(self, text: str) -> str:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not text:
            return ""

        result = text

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–≥–∏—Å—Ç—Ä–∞
        if self.config['preprocessing']['normalize_case']:
            result = result.lower()

        # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        if self.config['preprocessing']['remove_special_chars']:
            result = re.sub(r'[^\w\s\-]', ' ', result)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
        if self.config['preprocessing']['normalize_spaces']:
            result = re.sub(r'\s+', ' ', result).strip()

        # –û–±—â–∏–µ –∑–∞–º–µ–Ω—ã
        for old, new in self.config['preprocessing']['common_replacements'].items():
            result = result.replace(old, new)

        return result

    def _extract_brand_from_title(self, title: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è - –∏—â–µ—Ç —Å–ª–æ–≤–∞ –±–æ–ª—å—à–∏–º–∏ –±—É–∫–≤–∞–º–∏"""
        if not title:
            return ""
        
        words = title.split()
        brands = []
        
        for word in words:
            # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
            clean_word = word.strip('.,;:()[]{}!?-/')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –≤—Å–µ –±—É–∫–≤—ã –∑–∞–≥–ª–∞–≤–Ω—ã–µ –∏ –¥–ª–∏–Ω–∞ 2+ —Å–∏–º–≤–æ–ª–∞
            if clean_word.isupper() and len(clean_word) >= 2:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª—ã —Ç–∏–ø–∞ "–ú16", "S1" (–±—É–∫–≤–∞+—Ü–∏—Ñ—Ä—ã)
                if not any(char.isdigit() for char in clean_word):
                    brands.append(clean_word)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –±—Ä–µ–Ω–¥ –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        return brands[0] if brands else ""

    def _extract_size_from_title(self, title: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞"""
        # –ü–æ–∏—Å–∫ —Ä–∞–∑–º–µ—Ä–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (XS, S, M, L, XL, XXL)
        size_match = re.search(r'\b(XXL|XL|XS|[SML])\b', title.upper())
        return size_match.group(1) if size_match else ""

    def _get_confidence_level(self, score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏"""
        levels = self.config['confidence_levels']

        if score >= levels['high']:
            return "high"
        elif score >= levels['medium']:
            return "medium"
        else:
            return "low"

    def update_threshold(self, new_threshold: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏"""
        self.config['threshold'] = max(0.0, min(1.0, new_threshold))

    def get_statistics(self, matches: List[MatchResult]) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º"""
        if not matches:
            return {
                'total_matches': 0,
                'confidence_distribution': {'high': 0, 'medium': 0, 'low': 0},
                'average_similarity': 0.0,
                'marketplaces': {}
            }

        confidence_dist = {'high': 0, 'medium': 0, 'low': 0}
        marketplace_counts = {}

        for match in matches:
            confidence_dist[match.confidence] += 1
            marketplace_counts[match.marketplace] = marketplace_counts.get(match.marketplace, 0) + 1

        avg_similarity = sum(m.similarity_score for m in matches) / len(matches)

        return {
            'total_matches': len(matches),
            'confidence_distribution': confidence_dist,
            'average_similarity': round(avg_similarity, 3),
            'marketplaces': marketplace_counts
        }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    products_1c = [
        {
            'id': 'hjc-rpha71-xl',
            'name': '–ú–æ—Ç–æ—à–ª–µ–º HJC RPHA71 CARBON XL',
            'brand': 'HJC',
            'size': 'XL',
            'price': 63000
        }
    ]

    scraped_products = [
        {
            'title': 'HJC RPHA71 CARBON CARBON XL',
            'price': 63000,
            'marketplace': 'Mr-moto.ru'
        },
        {
            'title': '–®–ª–µ–º RPHA71 MATTE BLACK HJC XL',
            'price': 41690,
            'marketplace': 'Wildberries'
        }
    ]

    matcher = ProductMatcher()
    matches = matcher.match_products(products_1c, scraped_products)

    print(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(matches)}")
    for match in matches:
        print(f"- {match.product_1c_name} -> {match.scraped_product_title}")
        print(f"  –°—Ö–æ–∂–µ—Å—Ç—å: {match.similarity_score:.2f}, –¶–µ–Ω–∞: {match.price_1c} -> {match.price_scraped}")
