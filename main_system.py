"""
–ì–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ v3.0
–° –Ω–æ–≤—ã–º–∏ Selenium —Å–∫—Ä–∞–ø–µ—Ä–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞
"""

import logging
from pathlib import Path
from typing import List, Dict, Optional
import json
import csv
from datetime import datetime

from scrapers.scraper_manager import ScraperManager, ScrapedProduct
from commerceml_parser import CommerceMLParser
from product_matcher import ProductMatcher

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


class CompetitiveAnalysisSystem:
    """
    –°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ v3.0
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ –∏–∑ 1–° (XML/Excel)
    - –ü–∞—Ä—Å–∏–Ω–≥ 9 –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é Selenium
    - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤
    """
    
    def __init__(self, headless: bool = True):
        """
        Args:
            headless: –∑–∞–ø—É—Å–∫–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä—ã –±–µ–∑ GUI
        """
        self.headless = headless
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        self.scraper_manager = ScraperManager(headless=headless)
        self.xml_parser = CommerceMLParser()
        self.matcher = ProductMatcher()
        
        # –î–∞–Ω–Ω—ã–µ
        self.products_1c = []
        self.products_1c_limited = []  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        self.scraped_products = []
        self.matches = []
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        self.logger.info(f"   –†–µ–∂–∏–º –±—Ä–∞—É–∑–µ—Ä–∞: {'headless' if headless else '—Å GUI'}")
    
    def load_catalog_from_1c(self, file_path: str) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ 1–°
        
        Args:
            file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (XML –∏–ª–∏ Excel)
        
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        self.logger.info(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞: {file_path}")
        
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext in ['.xml']:
                # XML —Ñ–∞–π–ª
                success = self.xml_parser.parse(file_path)
                if success:
                    self.products_1c = self.xml_parser.get_products()
            
            elif file_ext in ['.xlsx', '.xls']:
                # Excel —Ñ–∞–π–ª (—Ñ–∞–π–ª –∏–∑ 1–°)
                from parse_1c_improved import Improved1CParser
                parser = Improved1CParser()
                self.products_1c = parser.parse(file_path)
            
            else:
                self.logger.error(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_ext}")
                return False
            
            if self.products_1c:
                self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(self.products_1c)}")
                return True
            else:
                self.logger.warning("‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ñ–∞–π–ª–µ")
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return False
    
    def scrape_competitors(
        self,
        sites: Optional[List[str]] = None,
        max_products_per_site: int = 20,
        max_products_from_1c: int = 5
    ) -> Dict[str, int]:
        """
        –ü–∞—Ä—Å–∏—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        
        Args:
            sites: —Å–ø–∏—Å–æ–∫ —Å–∞–π—Ç–æ–≤ (None = –≤—Å–µ)
            max_products_per_site: –º–∞–∫—Å —Ç–æ–≤–∞—Ä–æ–≤ —Å –∫–∞–∂–¥–æ–≥–æ —Å–∞–π—Ç–∞
            max_products_from_1c: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–° –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        
        Returns:
            —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ {—Å–∞–π—Ç: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ}
        """
        if not self.products_1c:
            self.logger.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ 1–°")
            return {}
        
        self.logger.info(f"üîç –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
        self.logger.info(f"   –¢–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–°: {max_products_from_1c}")
        self.logger.info(f"   –°–∞–π—Ç—ã: {sites if sites else '–≤—Å–µ'}")
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –Ω–æ–≤—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º
        self.scraped_products = []
        self.matches = []
        
        stats = {}
        
        # –í–ê–ñ–ù–û: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –ò –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ match_products –∏ generate_report
        self.products_1c_limited = self.products_1c[:max_products_from_1c]
        
        self.logger.info(f"   –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(self.products_1c_limited)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–° (–≤—Å–µ–≥–æ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ: {len(self.products_1c)})")
        
        for idx, product_1c in enumerate(self.products_1c_limited, 1):
            query = product_1c.get('name', '')
            
            if not query:
                continue
            
            self.logger.info(f"\nüì¶ [{idx}/{len(self.products_1c_limited)}] –¢–æ–≤–∞—Ä: {query}")
            
            # –ü–æ–∏—Å–∫ –Ω–∞ –≤—Å–µ—Ö —Å–∞–π—Ç–∞—Ö
            results = self.scraper_manager.search_all(
                query=query,
                sites=sites,
                max_products=max_products_per_site
            )
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for site, products in results.items():
                if site not in stats:
                    stats[site] = 0
                
                stats[site] += len(products)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                for product in products:
                    self.scraped_products.append(product.to_dict())
        
        self.logger.info(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")
        self.logger.info(f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(self.scraped_products)} —Ç–æ–≤–∞—Ä–æ–≤")
        
        return stats
    
    def match_products(self, threshold: float = 0.75) -> bool:
        """
        –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–≤–∞—Ä—ã –∏–∑ 1–° —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏
        
        Args:
            threshold: –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0-1)
        
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        if not self.products_1c or not self.scraped_products:
            self.logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è")
            return False
        
        self.logger.info(f"üîó –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ (–ø–æ—Ä–æ–≥: {threshold})")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–° –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        products_for_matching = self.products_1c_limited if self.products_1c_limited else self.products_1c
        
        self.matches = self.matcher.match_products(
            products_for_matching,
            self.scraped_products,
            threshold=threshold
        )
        
        self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(self.matches)}")
        
        return True
    
    def generate_report(self, format: str = 'json') -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç
        
        Args:
            format: —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞ (json, csv, excel)
        
        Returns:
            –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç—á–µ—Ç–∞
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_dir = Path('data/reports')
        report_dir.mkdir(parents=True, exist_ok=True)
        
        if format == 'json':
            report_path = report_dir / f'competitive_analysis_{timestamp}.json'
            
            # Convert MatchResult objects to dicts if needed
            matches_data = []
            for match in self.matches:
                if hasattr(match, 'to_dict'):
                    matches_data.append(match.to_dict())
                else:
                    matches_data.append(match)
            
            report_data = {
                'generated_at': datetime.now().isoformat(),
                'summary': {
                    'total_products_1c': len(self.products_1c),
                    'total_scraped_products': len(self.scraped_products),
                    'total_matches': len(self.matches),
                },
                'products_1c': self.products_1c,
                'scraped_products': self.scraped_products,
                'matches': matches_data,
            }
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        elif format == 'csv':
            import pandas as pd
            report_path = report_dir / f'analiz_{timestamp}.csv'
            
            # –°–æ–∑–¥–∞–µ–º —á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
            report_data = []
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ —Ç–æ–≤–∞—Ä–∞–º –∏–∑ 1–°
            products_with_matches = {}
            for match in self.matches:
                match_dict = match.to_dict() if hasattr(match, 'to_dict') else match
                product_id = match_dict.get('product_1c_id', '')
                
                if product_id not in products_with_matches:
                    products_with_matches[product_id] = {
                        'product': match_dict,
                        'matches': []
                    }
                products_with_matches[product_id]['matches'].append(match_dict)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –æ—Ç—á–µ—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–°, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω
            products_for_report = self.products_1c_limited if self.products_1c_limited else self.products_1c
            product_number = 1  # –°—á–µ—Ç—á–∏–∫ –¥–ª—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤
            
            for product_1c in products_for_report:
                product_id = product_1c.get('id', '')
                product_name = product_1c.get('name', '')
                product_price = product_1c.get('price', 0)
                
                if product_id in products_with_matches:
                    # –ï—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è - –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ–ª—É—á–∞—é—Ç –æ–¥–∏–Ω –Ω–æ–º–µ—Ä
                    matches = products_with_matches[product_id]['matches']
                    for match in matches:
                        report_data.append({    
                            '–ù—É–º–µ—Ä–∞—Ü–∏—è': product_number,
                            '–¢–æ–≤–∞—Ä 1–°': product_name,
                            '–ê—Ä—Ç–∏–∫—É–ª': product_id,
                            '–¶–µ–Ω–∞ 1–° (—Ä—É–±)': product_price,
                            '–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å': match.get('marketplace', ''),
                            '–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–µ': match.get('scraped_product_title', ''),
                            '–¶–µ–Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ (—Ä—É–±)': match.get('price_scraped', 0),
                            '–†–∞–∑–Ω–∏—Ü–∞ (—Ä—É–±)': match.get('price_difference', 0),
                            '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ (%)': round(match.get('similarity_score', 0) * 100, 1),
                            '–û—Ç–∑—ã–≤–æ–≤': match.get('reviews_count', 0),
                            '–†–µ–π—Ç–∏–Ω–≥': str(round(match.get('rating', 0.0), 1)).replace('.', ',') if match.get('rating', 0.0) > 0 else '',
                            '–°—Å—ã–ª–∫–∞': match.get('url', '')
                        })
                else:
                    # –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π - —Ç–æ–∂–µ –ø–æ–ª—É—á–∞–µ—Ç –Ω–æ–º–µ—Ä
                    report_data.append({
                        '–ù—É–º–µ—Ä–∞—Ü–∏—è': product_number,
                        '–¢–æ–≤–∞—Ä 1–°': product_name,
                        '–ê—Ä—Ç–∏–∫—É–ª': product_id,
                        '–¶–µ–Ω–∞ 1–° (—Ä—É–±)': product_price,
                        '–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ',
                        '–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–µ': '',
                        '–¶–µ–Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ (—Ä—É–±)': '',
                        '–†–∞–∑–Ω–∏—Ü–∞ (—Ä—É–±)': '',
                        '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ (%)': '',
                        '–û—Ç–∑—ã–≤–æ–≤': '',
                        '–†–µ–π—Ç–∏–Ω–≥': '',
                        '–°—Å—ã–ª–∫–∞': ''
                    })
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–æ–º–µ—Ä —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–æ–≤–∞—Ä—É
                product_number += 1
            
            if report_data:
                df = pd.DataFrame(report_data)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è –≤ Excel (—Ä—É—Å—Å–∫–∞—è –ª–æ–∫–∞–ª—å)
                # encoding='utf-8-sig' –¥–æ–±–∞–≤–ª—è–µ—Ç BOM –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
                # quoting=1 (QUOTE_ALL) - –≤—Å–µ –ø–æ–ª—è –≤ –∫–∞–≤—ã—á–∫–∞—Ö –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                df.to_csv(
                    report_path, 
                    index=False, 
                    encoding='utf-8-sig', 
                    sep=';',
                    quoting=csv.QUOTE_ALL,
                    escapechar=None
                )
            else:
                self.logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è CSV –æ—Ç—á–µ—Ç–∞")
                return ""
        
        elif format == 'excel':
            import pandas as pd
            report_path = report_dir / f'competitive_analysis_{timestamp}.xlsx'
            
            with pd.ExcelWriter(report_path, engine='openpyxl') as writer:
                if self.matches:
                    # Convert MatchResult objects to dicts if needed
                    matches_data = []
                    for match in self.matches:
                        if hasattr(match, 'to_dict'):
                            matches_data.append(match.to_dict())
                        else:
                            matches_data.append(match)
                    df_matches = pd.DataFrame(matches_data)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –ø–æ —Ç–æ–≤–∞—Ä–∞–º –∏–∑ 1–°
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ product_1c_id –∏ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞
                    if 'product_1c_id' in df_matches.columns:
                        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –≤ –ø–æ—Ä—è–¥–∫–µ –ø–æ—è–≤–ª–µ–Ω–∏—è
                        unique_products = df_matches['product_1c_id'].drop_duplicates().reset_index(drop=True)
                        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å: product_id -> –Ω–æ–º–µ—Ä
                        product_to_number = {product_id: idx + 1 for idx, product_id in enumerate(unique_products)}
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é
                        df_matches['–ù—É–º–µ—Ä–∞—Ü–∏—è'] = df_matches['product_1c_id'].map(product_to_number)
                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü –≤ –Ω–∞—á–∞–ª–æ
                        cols = ['–ù—É–º–µ—Ä–∞—Ü–∏—è'] + [col for col in df_matches.columns if col != '–ù—É–º–µ—Ä–∞—Ü–∏—è']
                        df_matches = df_matches[cols]
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç product_1c_id, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –Ω—É–º–µ—Ä–∞—Ü–∏—é
                        df_matches.insert(0, '–ù—É–º–µ—Ä–∞—Ü–∏—è', range(1, len(df_matches) + 1))
                    
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü "–†–∞–∑–Ω–∏—Ü–∞ (%)" –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                    if 'price_difference_percent' in df_matches.columns:
                        df_matches = df_matches.drop(columns=['price_difference_percent'])
                    
                    # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ—á–∫—É –Ω–∞ –∑–∞–ø—è—Ç—É—é –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Excel
                    if 'rating' in df_matches.columns:
                        df_matches['rating'] = df_matches['rating'].apply(
                            lambda x: str(x).replace('.', ',') if x and x != 0 and pd.notna(x) else ''
                        )
                    
                    df_matches.to_excel(writer, sheet_name='–°–æ–≤–ø–∞–¥–µ–Ω–∏—è', index=False)
                
                if self.products_1c:
                    df_1c = pd.DataFrame(self.products_1c)
                    df_1c.to_excel(writer, sheet_name='–¢–æ–≤–∞—Ä—ã 1–°', index=False)
                
                if self.scraped_products:
                    df_scraped = pd.DataFrame(self.scraped_products)
                    # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ—á–∫—É –Ω–∞ –∑–∞–ø—è—Ç—É—é –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Excel
                    if 'rating' in df_scraped.columns:
                        df_scraped['rating'] = df_scraped['rating'].apply(
                            lambda x: str(x).replace('.', ',') if x and x != 0 and pd.notna(x) else ''
                        )
                    df_scraped.to_excel(writer, sheet_name='–°–ø–∞—Ä—Å–µ–Ω–æ', index=False)
        
        else:
            self.logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")
            return ""
        
        self.logger.info(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")
        return str(report_path)
    
    def export_to_google_sheets(
        self,
        spreadsheet_id: str,
        credentials_path: str = 'credentials.json',
        sheet_name: str = 'Sheet1'
    ) -> bool:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ Google –¢–∞–±–ª–∏—Ü—É
        
        Args:
            spreadsheet_id: ID Google –¢–∞–±–ª–∏—Ü—ã (–∏–∑ URL)
            credentials_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å credentials Service Account
            sheet_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'Sheet1')
        
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            from google_sheets_exporter import GoogleSheetsExporter
            
            self.logger.info(f"üìä –≠–∫—Å–ø–æ—Ä—Ç –≤ Google –¢–∞–±–ª–∏—Ü—É: {spreadsheet_id}")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä
            exporter = GoogleSheetsExporter(credentials_path=credentials_path)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ –¥–ª—è CSV
            report_data = []
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ —Ç–æ–≤–∞—Ä–∞–º –∏–∑ 1–°
            products_with_matches = {}
            for match in self.matches:
                match_dict = match.to_dict() if hasattr(match, 'to_dict') else match
                product_id = match_dict.get('product_1c_id', '')
                
                if product_id not in products_with_matches:
                    products_with_matches[product_id] = {
                        'product': match_dict,
                        'matches': []
                    }
                products_with_matches[product_id]['matches'].append(match_dict)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –æ—Ç—á–µ—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã)
            products_for_report = self.products_1c_limited if self.products_1c_limited else self.products_1c
            product_number = 1
            
            for product_1c in products_for_report:
                product_id = product_1c.get('id', '')
                product_name = product_1c.get('name', '')
                product_price = product_1c.get('price', 0)
                
                if product_id in products_with_matches:
                    # –ï—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                    matches = products_with_matches[product_id]['matches']
                    for match in matches:
                        report_data.append({
                            '–ù—É–º–µ—Ä–∞—Ü–∏—è': product_number,
                            '–¢–æ–≤–∞—Ä 1–°': product_name,
                            '–ê—Ä—Ç–∏–∫—É–ª': product_id,
                            '–¶–µ–Ω–∞ 1–° (—Ä—É–±)': product_price,
                            '–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å': match.get('marketplace', ''),
                            '–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–µ': match.get('scraped_product_title', ''),
                            '–¶–µ–Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ (—Ä—É–±)': match.get('price_scraped', 0),
                            '–†–∞–∑–Ω–∏—Ü–∞ (—Ä—É–±)': match.get('price_difference', 0),
                            '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ (%)': round(match.get('similarity_score', 0) * 100, 1),
                            '–û—Ç–∑—ã–≤–æ–≤': match.get('reviews_count', 0),
                            '–†–µ–π—Ç–∏–Ω–≥': str(round(match.get('rating', 0.0), 1)).replace('.', ',') if match.get('rating', 0.0) > 0 else '',
                            '–°—Å—ã–ª–∫–∞': match.get('url', '')
                        })
                else:
                    # –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                    report_data.append({
                        '–ù—É–º–µ—Ä–∞—Ü–∏—è': product_number,
                        '–¢–æ–≤–∞—Ä 1–°': product_name,
                        '–ê—Ä—Ç–∏–∫—É–ª': product_id,
                        '–¶–µ–Ω–∞ 1–° (—Ä—É–±)': product_price,
                        '–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ',
                        '–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–µ': '',
                        '–¶–µ–Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ (—Ä—É–±)': '',
                        '–†–∞–∑–Ω–∏—Ü–∞ (—Ä—É–±)': '',
                        '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ (%)': '',
                        '–û—Ç–∑—ã–≤–æ–≤': '',
                        '–†–µ–π—Ç–∏–Ω–≥': '',
                        '–°—Å—ã–ª–∫–∞': ''
                    })
                
                product_number += 1
            
            if not report_data:
                self.logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Google Sheets")
                return False
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ Google Sheets
            success = exporter.export_to_sheet(
                spreadsheet_id=spreadsheet_id,
                data=report_data,
                sheet_name=sheet_name,
                clear_sheet=True
            )
            
            if success:
                self.logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ Google –¢–∞–±–ª–∏—Ü—É")
                self.logger.info(f"   –°—Å—ã–ª–∫–∞: {exporter.get_spreadsheet_url(spreadsheet_id)}")
            
            return success
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Google Sheets: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def get_status(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
        return {
            'products_1c_loaded': len(self.products_1c),
            'scraped_products': len(self.scraped_products),
            'matches_found': len(self.matches),
            'supported_sites': list(self.scraper_manager.get_supported_sites().keys()),
        }


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("=" * 80)
    print("  –°–ò–°–¢–ï–ú–ê –ö–û–ù–ö–£–†–ï–ù–¢–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê v3.0")
    print("=" * 80)
    print()
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    system = CompetitiveAnalysisSystem(headless=True)
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥
    print("üì¶ –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ –∏–∑ 1–°")
    success = system.load_catalog_from_1c("sample_commerceml.xml")
    
    if success:
        print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(system.products_1c)} —Ç–æ–≤–∞—Ä–æ–≤")
    
    # 2. –ü–∞—Ä—Å–∏–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    print("\nüîç –®–∞–≥ 2: –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
    stats = system.scrape_competitors(
        sites=['wildberries', 'ozon'],  # –¢–µ—Å—Ç–∏—Ä—É–µ–º 2 —Å–∞–π—Ç–∞
        max_products_per_site=5
    )
    
    print("\n   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    for site, count in stats.items():
        print(f"     {site}: {count} —Ç–æ–≤–∞—Ä–æ–≤")
    
    # 3. –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    print("\nüîó –®–∞–≥ 3: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤")
    system.match_products(threshold=0.70)
    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(system.matches)}")
    
    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
    print("\nüìä –®–∞–≥ 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤")
    json_report = system.generate_report('json')
    csv_report = system.generate_report('csv')
    
    print(f"   ‚úÖ JSON: {json_report}")
    print(f"   ‚úÖ CSV: {csv_report}")
    
    # –°—Ç–∞—Ç—É—Å
    print("\n" + "=" * 80)
    status = system.get_status()
    print("üìà –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –¢–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–°: {status['products_1c_loaded']}")
    print(f"   –°–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {status['scraped_products']}")
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {status['matches_found']}")
    print(f"   –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Å–∞–π—Ç—ã: {len(status['supported_sites'])}")
    
    print("\n" + "=" * 80)
    print("  ‚úÖ –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    print("=" * 80)
