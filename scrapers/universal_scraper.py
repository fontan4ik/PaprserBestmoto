"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π Selenium —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–æ–≤
–†–∞–±–æ—Ç–∞–µ—Ç —Å: mr-moto.ru, Flipup.ru, Pro-ekip.ru, Motoekip.su, Motocomfort.ru
–ù–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—á–µ—Ç–∞ –ø–æ –∏–Ω—Å–ø–µ–∫—Ü–∏–∏ mr-moto.ru
"""

import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time
import re
import logging
from dataclasses import dataclass
from typing import List, Optional
from urllib.parse import quote_plus
import random

@dataclass
class Product:
    title: str
    price: float
    old_price: Optional[float] = None
    url: str = ""
    source: str = ""
    availability: str = "unknown"
    brand: str = ""
    image_url: str = ""


class UniversalScraper:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–æ–≤
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–∞–π—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ
    """
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∞–π—Ç–æ–≤
    SITES_CONFIG = {
        'mr-moto.ru': {
            'search_url': 'https://mr-moto.ru/catalog/search/?q={query}',
            'product_card_selectors': ['div.slider-card', 'div.slider-card__box'],
            'title_selectors': [
                'div.slider-card__title a[href]',
                'div.slider-card__box a[href]'
            ],
            'brand_selectors': ['div.slider-card__box > div.slider-card__title a[target="_blank"]'],
            'price_selectors': [
                'div.slider-card__price-title',
                {'selector': 'meta[itemprop="lowPrice"]', 'attr': 'content'},
            ],
        },
        'flipup.ru': {
            'search_url': 'https://flipup.ru/search/?q={query}',
            'product_card_selectors': ['div.product-card', 'div.product-item'],
            'title_selectors': [
                'a.name span.middle',
                'a.name'
            ],
            'price_selectors': [
                'a.price',
                'div.price',
                'span.price'
            ],
        },
        'pro-ekip.ru': {
            'search_url': 'https://pro-ekip.ru/catalog/?q={query}',
            'product_card_selectors': ['div.item', 'div.product', 'div.catalog-item'],
            'title_selectors': [
                'a.thumb.shine',
                'a.thumb',
                'a.title'
            ],
            'price_selectors': [
                {'selector': 'span.to-cart', 'attr': 'data-value'},
                'div.cost',
                'span.price'
            ],
        },
        'motoekip.su': {
            'search_url': 'https://motoekip.su/index.php?route=product/search&search={query}',
            'product_card_selectors': ['div.digi-product', 'div.digi-product__layout'],
            'title_selectors': [
                'a.digi-product__label',
                'a.digi-product__brand'
            ],
            'brand_selectors': ['a.digi-product__brand'],
            'price_selectors': [
                'span.digi-product-price-variant_actual',
                'div.digi-product__price'
            ],
        },
        'motocomfort.ru': {
            'search_url': 'https://motocomfort.ru/search/?query={query}',
            'product_card_selectors': ['div.c-product-thumb', 'div.c-product-thumb__wrapper'],
            'title_selectors': [
                'div.c-product-thumb__name a',
                {'selector': 'img.c-product-thumb__image', 'attr': 'data-alt'},
                {'selector': 'img.c-product-thumb__image', 'attr': 'alt'},
            ],
            'price_selectors': [
                'div.c-product-thumb__price',
                'span.c-product-thumb__price',
                'span.price'
            ],
        },
    }
    
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.driver = None
        self.logger = logging.getLogger(__name__)
        logging.basicConfig(level=logging.INFO)
    
    def _init_driver(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞"""
        if self.driver:
            return
        
        try:
            options = uc.ChromeOptions()
            
            if self.headless:
                options.add_argument('--headless=new')
            
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            
            self.driver = uc.Chrome(options=options)
            self.driver.set_page_load_timeout(45)  # –£–≤–µ–ª–∏—á–µ–Ω timeout
            
            self.logger.info("‚úÖ Chrome –¥—Ä–∞–π–≤–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            raise
    
    def search(self, site: str, query: str, max_products: int = 20) -> List[Product]:
        """
        –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Å–∞–π—Ç–µ
        
        Args:
            site: –¥–æ–º–µ–Ω —Å–∞–π—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'mr-moto.ru')
            query: –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            max_products: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
        """
        products = []
        
        try:
            self._init_driver()
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–∞–π—Ç–∞
            config = self.SITES_CONFIG.get(site)
            
            if not config:
                self.logger.warning(f"‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è {site} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥.")
                config = {
                    'search_url': f'https://{site}/search?q={{query}}',
                    'product_card_selectors': ['div.product', 'div.item', 'article'],
                    'title_selectors': ['h3', 'h2', 'a.title', 'a.name'],
                    'price_selectors': ['span.price', 'div.price', 'span.cost'],
                }
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL
            search_url = config['search_url'].format(query=quote_plus(query))
            
            self.logger.info(f"üîç –ü–æ–∏—Å–∫ –Ω–∞ {site}: {query}")
            self.logger.info(f"üìç URL: {search_url}")
            
            self.driver.get(search_url)
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
            time.sleep(random.uniform(2, 4))
            
            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º
            self._scroll_page()
            
            # –ü–∞—Ä—Å–∏–º
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤
            cards = self._find_product_cards(soup, config.get('product_card_selectors', []))
            
            self.logger.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫: {len(cards)}")
            
            for card in cards[:max_products]:
                try:
                    product = self._parse_product_card(card, config, site)
                    if product:
                        products.append(product)
                except Exception as e:
                    self.logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
                    continue
            
            self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        
        return products
    
    def _find_product_cards(self, soup, selectors):
        """–ò—â–µ—Ç –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        for selector in selectors or []:
            cards = []
            try:
                cards = soup.select(selector)
            except Exception:
                # –ü–∞–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ find_all –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
                if '.' in selector:
                    tag, class_name = selector.split('.', 1)
                    cards = soup.find_all(tag, class_=lambda x: x and class_name in str(x))
                else:
                    cards = soup.find_all(selector)
            if cards:
                return cards
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ
        cards = soup.find_all('div', class_=lambda x: x and any(
            word in str(x).lower() for word in ['product', 'item', 'goods', 'catalog']
        ))
        
        return cards
    
    def _extract_value_by_selectors(self, node, selectors):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç/–∞—Ç—Ä–∏–±—É—Ç –ø–µ—Ä–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ —Å–ø–∏—Å–∫—É —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        if not selectors:
            return ""
        
        for selector in selectors:
            attr = 'text'
            css = selector
            if isinstance(selector, dict):
                css = selector.get('selector')
                attr = selector.get('attr', 'text')
            if not css:
                continue
            try:
                element = node.select_one(css)
            except Exception:
                element = None
            if not element:
                continue
            
            if attr == 'text':
                value = element.get_text(strip=True)
            else:
                value = element.get(attr)
            
            if value:
                return str(value).strip()
        
        return ""
    
    def _scroll_page(self):
        """–ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
        try:
            for i in range(2):
                self.driver.execute_script(f"window.scrollTo(0, {1000 * (i + 1)});")
                time.sleep(1)
            
            self.driver.execute_script("window.scrollTo(0, 300);")
            time.sleep(0.5)
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–∫—Ä—É—Ç–∫–∏: {e}")
    
    def _parse_product_card(self, card, config, site) -> Optional[Product]:
        """–ü–∞—Ä—Å–∏—Ç –∫–∞—Ä—Ç–æ—á–∫—É —Ç–æ–≤–∞—Ä–∞"""
        try:
            # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
            link = card.find('a', href=True)
            if not link:
                return None
            
            href = link.get('href', '')
            if not href.startswith('http'):
                href = f"https://{site}{href if href.startswith('/') else '/' + href}"
            
            product_url = href.split('?')[0]
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ
            title = self._extract_value_by_selectors(card, config.get('title_selectors'))
            if not title:
                title = link.get('title', '') or link.get_text(strip=True)
            
            if not title or len(title) < 3:
                return None
            
            # –ë—Ä–µ–Ω–¥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            brand = self._extract_value_by_selectors(card, config.get('brand_selectors'))
            
            # –¶–µ–Ω–∞
            price = 0.0
            old_price = None
            price_text = self._extract_value_by_selectors(card, config.get('price_selectors'))
            if price_text:
                price = self._extract_price(price_text)
            
            # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—â–µ–º –ª—é–±–æ–π —Ç–µ–∫—Å—Ç —Å —Ä—É–±–ª—è–º–∏
            if price == 0:
                price_elem = card.find(string=lambda x: x and '‚ÇΩ' in str(x))
                if price_elem:
                    price = self._extract_price(price_elem)
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_url = ""
            img = card.find('img')
            if img:
                image_url = img.get('src', '') or img.get('data-src', '')
                if image_url and not image_url.startswith('http'):
                    image_url = f"https://{site}{image_url}"
            
            if price > 0:
                return Product(
                    title=title[:200],
                    price=price,
                    old_price=old_price,
                    url=product_url,
                    source=site,
                    availability="in_stock",
                    brand=brand or "",
                    image_url=image_url
                )
            
            return None
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
            return None
    
    def _extract_price(self, price_text: str) -> float:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É"""
        if not price_text:
            return 0.0
        
        text = str(price_text).replace('\xa0', '').replace(' ', '')
        match = re.search(r'(\d+[.,]?\d*)', text)
        if not match:
            return 0.0
        
        number_str = match.group(1).replace(',', '.')
        try:
            return float(number_str)
        except Exception:
            return 0.0
    
    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä"""
        if self.driver:
            try:
                self.driver.quit()
                self.logger.info("üîí –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            except (OSError, Exception) as e:
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —Å –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏
                if "WinError 6" not in str(e):
                    self.logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            finally:
                self.driver = None
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("=" * 80)
    print("  –¢–ï–°–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û–ì–û SCRAPER")
    print("=" * 80)
    print()
    
    with UniversalScraper(headless=False) as scraper:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Å–∞–π—Ç–∞—Ö
        sites = ['mr-moto.ru', 'flipup.ru']
        query = "–º–æ—Ç–æ—à–ª–µ–º"
        
        for site in sites:
            print(f"\nüîç –°–∞–π—Ç: {site}")
            print(f"   –ó–∞–ø—Ä–æ—Å: '{query}'")
            print("-" * 80)
            
            products = scraper.search(site, query, max_products=3)
            
            if products:
                print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤\n")
                
                for i, product in enumerate(products, 1):
                    print(f"{i}. {product.title[:60]}...")
                    print(f"   üí∞ –¶–µ–Ω–∞: {product.price:,.0f}‚ÇΩ")
                    print(f"   üîó {product.url}\n")
            else:
                print("\n‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
            time.sleep(2)
    
    print("=" * 80)
    print("  ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    print("=" * 80)
