"""
Selenium —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è Avito
–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ –ø–∞—Ä—Å–∏–Ω–≥—É Avito
"""

import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time
import re
import logging
from dataclasses import dataclass
from typing import List, Optional
from urllib.parse import quote
import random

@dataclass
class Product:
    title: str
    price: float
    old_price: Optional[float] = None
    url: str = ""
    source: str = "Avito"
    availability: str = "unknown"
    location: str = ""
    seller: str = ""
    image_url: str = ""
    reviews_count: int = 0
    rating: float = 0.0


class AvitoScraper:
    """Selenium —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è Avito"""
    
    def __init__(self, headless: bool = True, city: str = "rossiya"):
        self.headless = headless
        self.city = city  # rossiya, moskva, sankt-peterburg –∏ —Ç.–¥.
        self.driver = None
        self.logger = logging.getLogger(__name__)
        logging.basicConfig(level=logging.INFO)
    
    def _init_driver(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞"""
        if self.driver:
            return
        
        try:
            options = uc.ChromeOptions()
            
            if self.headless:
                options.add_argument('--headless=new')
            
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            
            self.driver = uc.Chrome(options=options)
            self.driver.set_page_load_timeout(60)  # –£–≤–µ–ª–∏—á–µ–Ω timeout –¥–ª—è Avito (—á–∞—Å—Ç–æ –º–µ–¥–ª–µ–Ω–Ω—ã–π)
            
            self.logger.info("‚úÖ Chrome –¥—Ä–∞–π–≤–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            raise
    
    def search(self, query: str, max_products: int = 20) -> List[Product]:
        """–ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ Avito"""
        products = []
        
        try:
            self._init_driver()
            
            # Avito URL: https://www.avito.ru/{–≥–æ—Ä–æ–¥}?q={–∑–∞–ø—Ä–æ—Å}
            search_url = f"https://www.avito.ru/{self.city}?q={quote(query)}"
            
            self.logger.info(f"üîç –ü–æ–∏—Å–∫ –Ω–∞ Avito: {query}")
            self.logger.info(f"üìç URL: {search_url}")
            
            self.driver.get(search_url)
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
            time.sleep(random.uniform(3, 5))
            
            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º
            self._scroll_page()
            
            # –ü–∞—Ä—Å–∏–º
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # Avito –∏—Å–ø–æ–ª—å–∑—É–µ—Ç data-marker –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            cards = soup.find_all(attrs={'data-marker': 'item'})
            
            if not cards:
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
                cards = soup.find_all('div', class_=lambda x: x and 'item' in str(x).lower())
            
            self.logger.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫: {len(cards)}")
            
            for card in cards[:max_products]:
                try:
                    product = self._parse_product_card(card)
                    if product:
                        products.append(product)
                except Exception as e:
                    self.logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                    continue
            
            self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        
        return products
    
    def _scroll_page(self):
        """–ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
        try:
            for i in range(3):
                self.driver.execute_script(f"window.scrollTo(0, {1000 * (i + 1)});")
                time.sleep(1.5)
            
            self.driver.execute_script("window.scrollTo(0, 500);")
            time.sleep(1)
            
        except Exception as e:
            pass
    
    def _parse_product_card(self, card) -> Optional[Product]:
        """
        –ü–∞—Ä—Å–∏—Ç –∫–∞—Ä—Ç–æ—á–∫—É —Ç–æ–≤–∞—Ä–∞ Avito
        
        –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
        - data-marker="item-title" - –Ω–∞–∑–≤–∞–Ω–∏–µ
        - data-marker="item-price" - —Ü–µ–Ω–∞
        - href —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–æ–≤–∞—Ä
        """
        try:
            # –°—Å—ã–ª–∫–∞
            link = card.find('a', attrs={'data-marker': 'item-title'})
            if not link:
                link = card.find('a', href=lambda x: x and '/items/' in str(x))
            
            if not link:
                return None
            
            href = link.get('href', '')
            if not href.startswith('http'):
                href = f"https://www.avito.ru{href}"
            
            product_url = href.split('?')[0]
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ
            title = link.get('title', '') or link.get_text(strip=True)
            
            if not title or len(title) < 5:
                title_elem = card.find(attrs={'data-marker': 'item-title'})
                if title_elem:
                    title = title_elem.get_text(strip=True)
            
            if not title or len(title) < 5:
                return None
            
            # –¶–µ–Ω–∞
            price = 0.0
            price_elem = card.find(attrs={'data-marker': 'item-price'})
            
            if not price_elem:
                price_elem = card.find(string=lambda x: x and '‚ÇΩ' in str(x))
            
            if price_elem:
                price_text = price_elem if isinstance(price_elem, str) else price_elem.get_text(strip=True)
                price = self._extract_price(price_text)
            
            # –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ
            location = ""
            location_elem = card.find(attrs={'data-marker': 'item-address'})
            if location_elem:
                location = location_elem.get_text(strip=True)
            
            # –ü—Ä–æ–¥–∞–≤–µ—Ü
            seller = ""
            seller_elem = card.find(attrs={'data-marker': 'seller-info'})
            if seller_elem:
                seller = seller_elem.get_text(strip=True)

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
            reviews_count = 0
            reviews_elem = card.find(attrs={'data-marker': 'seller-info/summary'})
            if reviews_elem:
                reviews_text = reviews_elem.get_text(strip=True)
                reviews_match = re.search(r'(\d[\d\s]*)', reviews_text)
                if reviews_match:
                    try:
                        reviews_count = int(re.sub(r'\s+', '', reviews_match.group(1)))
                    except ValueError:
                        reviews_count = 0

            # –†–µ–π—Ç–∏–Ω–≥ –ø—Ä–æ–¥–∞–≤—Ü–∞
            rating = 0.0
            rating_elem = card.find(attrs={'data-marker': 'seller-rating/score'})
            if rating_elem:
                rating_text = rating_elem.get_text(strip=True).replace(',', '.')
                try:
                    rating = float(re.sub(r'[^\d\.]', '', rating_text))
                except ValueError:
                    rating = 0.0

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ —Å –æ—Ç–∑—ã–≤–∞–º–∏ < 50
            if reviews_count < 50:
                return None
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_url = ""
            img = card.find('img')
            if img:
                image_url = img.get('src', '') or img.get('data-src', '')
            
            if price > 0:
                return Product(
                    title=title[:200],
                    price=price,
                    url=product_url,
                    source="Avito",
                    availability="in_stock",
                    location=location,
                    seller=seller,
                    image_url=image_url,
                    reviews_count=reviews_count,
                    rating=rating
                )
            
            return None
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
            return None
    
    def _extract_price(self, price_text: str) -> float:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É"""
        if not price_text:
            return 0.0
        
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä
        clean_text = re.sub(r'[^\d]', '', str(price_text))
        
        try:
            return float(clean_text) if clean_text else 0.0
        except:
            return 0.0
    
    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä"""
        if self.driver:
            try:
                self.driver.quit()
                self.logger.info("üîí –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            except (OSError, Exception) as e:
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —Å –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏
                if "WinError 6" not in str(e):
                    pass
            finally:
                self.driver = None
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("=" * 80)
    print("  –¢–ï–°–¢ AVITO SCRAPER")
    print("=" * 80)
    print()
    
    with AvitoScraper(headless=False, city="rossiya") as scraper:
        queries = ["–º–æ—Ç–æ—à–ª–µ–º HJC", "–º–æ—Ç–æ—ç–∫–∏–ø–∏—Ä–æ–≤–∫–∞"]
        
        for query in queries:
            print(f"\nüîç –ü–æ–∏—Å–∫: '{query}'")
            print("-" * 80)
            
            products = scraper.search(query, max_products=5)
            
            if products:
                print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤\n")
                
                for i, product in enumerate(products, 1):
                    print(f"{i}. {product.title[:60]}...")
                    print(f"   üí∞ –¶–µ–Ω–∞: {product.price:,.0f}‚ÇΩ")
                    if product.location:
                        print(f"   üìç –ú–µ—Å—Ç–æ: {product.location}")
                    print(f"   üîó {product.url}\n")
            else:
                print("\n‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
            time.sleep(2)
    
    print("=" * 80)
    print("  ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    print("=" * 80)
